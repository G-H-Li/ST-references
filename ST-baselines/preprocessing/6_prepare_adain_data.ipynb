{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4acebf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "from IPython.display import clear_output\n",
    "from multiprocessing import Pool\n",
    "from time import time\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd8fe341",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e39505",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad783258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_features(i):\n",
    "    # For train data\n",
    "    station_metaq_data = []\n",
    "    station_dist_data = []\n",
    "    local_met_data = []\n",
    "    local_aq_data = []\n",
    "    local_stations = []\n",
    "    \n",
    "    tmp_df = train_data.loc[time_range[i:i+time_window]]\n",
    "    for station in train_stations:\n",
    "        # Station side\n",
    "        station_side = tmp_df[tmp_df.station_id != station]\n",
    "        station_met_aq = station_side.drop(columns=['station_id', 'longitude', 'latitude', 'filled'])\n",
    "#         clear_output(wait=True)\n",
    "#         print('station_features', station_met_aq.columns)\n",
    "        station_met_aq2 = np.array(np.split(station_met_aq.values, time_window, axis=0)).swapaxes(0,1).swapaxes(1,2)[np.newaxis, :]\n",
    "        station_metaq_data.append(station_met_aq2)\n",
    "        \n",
    "        # Local side\n",
    "        local_side = tmp_df[tmp_df.station_id == station]\n",
    "        local_stations.append(local_side['station_id'].values[-1].reshape(-1,1))\n",
    "        local_met = local_side.drop(columns=['station_id', 'longitude', 'latitude', 'PM25_Concentration', 'filled']).values.swapaxes(0,1)[np.newaxis, :]\n",
    "        local_met_data.append(local_met)\n",
    "        local_aq = local_side['PM25_Concentration'].values[-1].reshape(-1,1)\n",
    "        local_aq_data.append(local_aq)\n",
    "        \n",
    "        station_dist = (station_side.drop_duplicates('station_id')[['longitude', 'latitude']].values -\\\n",
    "        local_side.drop_duplicates('station_id')[['longitude', 'latitude']].values)[np.newaxis, :]\n",
    "        station_dist_data.append(station_dist)\n",
    "    return [np.concatenate(station_metaq_data), \n",
    "            np.concatenate(station_dist_data), \n",
    "            np.concatenate(local_met_data), \n",
    "            np.concatenate(local_aq_data),\n",
    "            np.concatenate(local_stations)]\n",
    "\n",
    "def get_test_features(i):\n",
    "    # For test data\n",
    "    station_metaq_data = []\n",
    "    station_dist_data = []\n",
    "    local_met_data = []\n",
    "    local_aq_data = []\n",
    "    local_stations = []\n",
    "    \n",
    "    tmp_df_tst = test_data.loc[time_range[i:i+time_window]]\n",
    "    \n",
    "    station_side = train_data.loc[time_range[i:i+time_window]]\n",
    "    station_met_aq = station_side.drop(columns=['station_id', 'longitude', 'latitude', 'filled'])\n",
    "#     clear_output(wait=True)\n",
    "#     print('station_features', station_met_aq.columns)\n",
    "    station_met_aq2 = np.array(np.split(station_met_aq.values, time_window, axis=0)).swapaxes(0,1).swapaxes(1,2)[np.newaxis, :]\n",
    "    \n",
    "    for station in test_stations:\n",
    "        station_metaq_data.append(station_met_aq2)\n",
    "        \n",
    "        # Local side\n",
    "        local_side = tmp_df_tst[tmp_df_tst.station_id == station]\n",
    "        local_stations.append(local_side['station_id'].values[-1].reshape(-1,1))\n",
    "        local_met = local_side.drop(columns=['station_id', 'longitude', 'latitude', \n",
    "                                             'PM25_Concentration', 'filled']).values.swapaxes(0,1)[np.newaxis, :]\n",
    "        local_met_data.append(local_met)\n",
    "#         print('local_features', local_met.columns)\n",
    "        local_aq = local_side['PM25_Concentration'].values[-1].reshape(-1,1)\n",
    "        local_aq_data.append(local_aq)\n",
    "        \n",
    "        station_dist = (station_side.drop_duplicates('station_id')[['longitude', 'latitude']].values -\\\n",
    "        local_side.drop_duplicates('station_id')[['longitude', 'latitude']].values)[np.newaxis, :]\n",
    "        station_dist_data.append(station_dist)\n",
    "    \n",
    "    return [np.concatenate(station_metaq_data), \n",
    "            np.concatenate(station_dist_data), \n",
    "            np.concatenate(local_met_data), \n",
    "            np.concatenate(local_aq_data),\n",
    "            np.concatenate(local_stations)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44e79da",
   "metadata": {},
   "source": [
    "### Execute (notice we choose only a month worth data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d887eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2\n",
      "train finished\n",
      "test finished\n",
      "0.32884647448857623 minutes\n"
     ]
    }
   ],
   "source": [
    "init = time()\n",
    "fold=2 # not using for loop to avoid ram overflow\n",
    "print('fold', fold)\n",
    "\n",
    "train_data = pd.read_csv('../data/processed/fold_'+str(fold)+'_train_mar.csv.gz')\n",
    "train_data['time'] = pd.to_datetime(train_data['time'])\n",
    "train_data = train_data.set_index('time').sort_values(['time', 'station_id'])['2015-03-01':'2015-03-31']\n",
    "test_data = pd.read_csv('../data/processed/fold_'+str(fold)+'_test_mar.csv.gz')\n",
    "test_data['time'] = pd.to_datetime(test_data['time'])\n",
    "test_data = test_data.set_index('time').sort_values(['time', 'station_id'])['2015-03-01':'2015-03-31']\n",
    "\n",
    "# cols_to_scale = list(train_data.columns)\n",
    "cols_to_scale = ['temperature','latitude','longitude','wind_speed','humidity']\n",
    "# cols_to_scale.remove('station_id')\n",
    "# cols_to_scale.remove('time')\n",
    "# cols_to_scale.remove('PM25_Concentration')\n",
    "scaler =  RobustScaler().fit(train_data[cols_to_scale])\n",
    "train_data[cols_to_scale] = scaler.transform(train_data[cols_to_scale])\n",
    "test_data[cols_to_scale] = scaler.transform(test_data[cols_to_scale])\n",
    "                                             \n",
    "train_stations = train_data.station_id.unique()\n",
    "test_stations = test_data.station_id.unique()\n",
    "\n",
    "time_range = train_data.index.unique()\n",
    "workers = Pool(26)\n",
    "train_combo = workers.map(get_train_features, range(len(time_range)-24+1))\n",
    "print('train finished')\n",
    "test_combo = workers.map(get_test_features, range(len(time_range)-24+1))\n",
    "print('test finished')\n",
    "workers.close()\n",
    "\n",
    "for combo_data, name in zip([train_combo, test_combo], ['train', 'test']):\n",
    "#     station_metaq_data = np.concatenate([combo[0] for combo in combo_data])\n",
    "#     station_dist_data = np.concatenate([combo[1] for combo in combo_data])\n",
    "#     local_met_data = np.concatenate([combo[2] for combo in combo_data])\n",
    "#     local_aq_data = np.concatenate([combo[3] for combo in combo_data])\n",
    "      local_stations = np.concatenate([combo[4] for combo in combo_data])\n",
    "#     np.savez('../data/adain/fold_'+str(fold)+'_station_metaq_data_'+name, station_metaq_data)\n",
    "#     np.savez('../data/adain/fold_'+str(fold)+'_station_dist_data_'+name, station_dist_data)\n",
    "#     np.savez('../data/adain/fold_'+str(fold)+'_local_met_data_'+name, local_met_data)\n",
    "#     np.savez('../data/adain/fold_'+str(fold)+'_local_aq_data_'+name, local_aq_data)\n",
    "      np.savez('../data/adain/fold_'+str(fold)+'_local_stationids_'+name, local_stations)\n",
    "\n",
    "#     del station_metaq_data\n",
    "#     del local_met_data\n",
    "\n",
    "print((time()-init)/60, 'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03291bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
